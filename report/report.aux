\relax 
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{silver2016mastering}
\citation{mnih2013playing}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The agent-environment interaction loop.\relax }}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:agent_env}{{1}{2}}
\citation{bertsekas1995neuro}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces 5x5 board of Snake where the snake consists of the orange (head) and green parts (body) and the red part is the apple.\relax }}{3}}
\newlabel{fig:snake}{{2}{3}}
\citation{bellman1952theory}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces $\epsilon $-Greedy Policy\relax }}{7}}
\newlabel{alg:epsilon_greedy_policy}{{1}{7}}
\citation{watkins1989learning}
\citation{lange2010deep}
\citation{van2016deep}
\citation{sutton1998reinforcement}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces TD Learning Algorithm\relax }}{8}}
\newlabel{alg:td_learning}{{2}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Results generated by Q-Learning. Upper: Board state. Lower: Directional State.\relax }}{12}}
\newlabel{fig:reward_result_qlearning}{{3}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Results generated by Sarsa. Upper: Board state. Lower: Directional State.\relax }}{13}}
\newlabel{fig:reward_result_sarsa}{{4}{13}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The average correlation between the reward functions and game score.\relax }}{14}}
\newlabel{tab:reward_game_score_corr}{{1}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Board state with different augmented information.\relax }}{15}}
\newlabel{fig:info_augmentation_board_state}{{5}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Performance of state representations trained using Q-learning.\relax }}{16}}
\newlabel{fig:state_qlearning}{{6}{16}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Test performance over 10000 episodes.\relax }}{16}}
\newlabel{table:state_qlearning}{{2}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Performance of state representations trained using Sarsa.\relax }}{17}}
\newlabel{fig:state_sarsa}{{7}{17}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Test performance over 10000 episodes.\relax }}{17}}
\newlabel{table:state_sarsa}{{3}{17}}
\citation{hasselt2010double}
\citation{lin1992self}
\bibstyle{plain}
\bibdata{references}
\bibcite{bellman1952theory}{1}
\bibcite{bertsekas1995neuro}{2}
\bibcite{hasselt2010double}{3}
\bibcite{lange2010deep}{4}
\bibcite{lin1992self}{5}
\bibcite{mnih2013playing}{6}
\bibcite{silver2016mastering}{7}
\bibcite{sutton1998reinforcement}{8}
\bibcite{van2016deep}{9}
\bibcite{watkins1989learning}{10}
\@writefile{toc}{\contentsline {section}{\numberline {A}Reward Experiment}{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Q-Learning}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Performance of reward functions trained using Q-learning with the board state representation.\relax }}{22}}
\newlabel{fig:app_reward_qlearning}{{8}{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Sarsa}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Performance of reward functions trained using Sarsa with the board state representation.\relax }}{23}}
\newlabel{fig:app_reward_sarsa}{{9}{23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Expected Sarsa}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Performance of reward functions trained using Expected Sarsa with the board state representation.\relax }}{24}}
\newlabel{fig:app_reward_expected_sarsa}{{10}{24}}
\@writefile{toc}{\contentsline {section}{\numberline {B}State Experiment}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}Q-Learning}{25}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Performance of state representations trained using Q-learning.\relax }}{25}}
\newlabel{fig:app_state_qlearning}{{11}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}Sarsa}{26}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Performance of state representations trained using Sarsa.\relax }}{26}}
\newlabel{fig:app_state_sarsa}{{12}{26}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3}Expected Sarsa}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Performance of state representations trained using Expected Sarsa.\relax }}{27}}
\newlabel{fig:app_state_expected_sarsa}{{13}{27}}
